{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Training_utils\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import tb_utils\n",
    "importlib.reload(tb_utils)\n",
    "from tb_utils import *\n",
    "importlib.reload(Training_utils)\n",
    "from Training_utils import *\n",
    "from Image_Process_utils import *\n",
    "import model_utils\n",
    "importlib.reload(model_utils)\n",
    "from model_utils import *\n",
    "from Dataset_utils import *\n",
    "if not os.path.exists('./checkpoints'):\n",
    "    os.mkdir('./checkpoints')\n",
    "import arg_parser\n",
    "importlib.reload(arg_parser) \n",
    "from arg_parser import common_arg_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global t_step\n",
    "global v_step\n",
    "global test_step\n",
    "global micro_step\n",
    "global v_micro\n",
    "t_step = v_step = test_step = micro_step = v_micro = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_parser =common_arg_parser()\n",
    "args, unknown_args = arg_parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "batch_size =12\n",
    "my_transforms = transforms.Compose([\n",
    "    #transforms.Normalize((0.5,), (0.5,)),\n",
    "    Rescale(256),\n",
    "    Tensorize()\n",
    "    ])\n",
    "img_dir = './Acu_Dataset/sotack/org'\n",
    "json_file = './Acu_Dataset/sotack/sotack_info.json'\n",
    "\n",
    "sotack_dataset = HandDataSet(json_file, img_dir, transform = my_transforms, train=True) # pytorch 로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file) as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_size = int(len(sotack_dataset) * 0.1)\n",
    "train_set_size = len(sotack_dataset) - test_set_size\n",
    "train_set, test_set = torch.utils.data.random_split(sotack_dataset, [train_set_size, test_set_size])\n",
    "\n",
    "valid_set_size = int((train_set_size)*0.1) \n",
    "train_set_size = train_set_size - valid_set_size\n",
    "\n",
    "train_set, valid_set  = torch.utils.data.random_split(train_set, [train_set_size, valid_set_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size = 32, shuffle = True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_set, batch_size = 32, shuffle = True, num_workers=4)\n",
    "test_loader = DataLoader(test_set, batch_size = 32, shuffle = True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 350, 350]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 350, 350]             128\n",
      "              ReLU-3         [-1, 64, 350, 350]               0\n",
      "         MaxPool2d-4         [-1, 64, 175, 175]               0\n",
      "            Conv2d-5         [-1, 64, 175, 175]          36,864\n",
      "       BatchNorm2d-6         [-1, 64, 175, 175]             128\n",
      "              ReLU-7         [-1, 64, 175, 175]               0\n",
      "            Conv2d-8         [-1, 64, 175, 175]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 175, 175]             128\n",
      "             ReLU-10         [-1, 64, 175, 175]               0\n",
      "       BasicBlock-11         [-1, 64, 175, 175]               0\n",
      "           Conv2d-12         [-1, 64, 175, 175]          36,864\n",
      "      BatchNorm2d-13         [-1, 64, 175, 175]             128\n",
      "             ReLU-14         [-1, 64, 175, 175]               0\n",
      "           Conv2d-15         [-1, 64, 175, 175]          36,864\n",
      "      BatchNorm2d-16         [-1, 64, 175, 175]             128\n",
      "             ReLU-17         [-1, 64, 175, 175]               0\n",
      "       BasicBlock-18         [-1, 64, 175, 175]               0\n",
      "           Conv2d-19         [-1, 64, 175, 175]          36,864\n",
      "      BatchNorm2d-20         [-1, 64, 175, 175]             128\n",
      "             ReLU-21         [-1, 64, 175, 175]               0\n",
      "           Conv2d-22         [-1, 64, 175, 175]          36,864\n",
      "      BatchNorm2d-23         [-1, 64, 175, 175]             128\n",
      "             ReLU-24         [-1, 64, 175, 175]               0\n",
      "       BasicBlock-25         [-1, 64, 175, 175]               0\n",
      "           Conv2d-26          [-1, 128, 88, 88]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 88, 88]             256\n",
      "             ReLU-28          [-1, 128, 88, 88]               0\n",
      "           Conv2d-29          [-1, 128, 88, 88]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 88, 88]             256\n",
      "           Conv2d-31          [-1, 128, 88, 88]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 88, 88]             256\n",
      "             ReLU-33          [-1, 128, 88, 88]               0\n",
      "       BasicBlock-34          [-1, 128, 88, 88]               0\n",
      "           Conv2d-35          [-1, 128, 88, 88]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 88, 88]             256\n",
      "             ReLU-37          [-1, 128, 88, 88]               0\n",
      "           Conv2d-38          [-1, 128, 88, 88]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 88, 88]             256\n",
      "             ReLU-40          [-1, 128, 88, 88]               0\n",
      "       BasicBlock-41          [-1, 128, 88, 88]               0\n",
      "           Conv2d-42          [-1, 128, 88, 88]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 88, 88]             256\n",
      "             ReLU-44          [-1, 128, 88, 88]               0\n",
      "           Conv2d-45          [-1, 128, 88, 88]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 88, 88]             256\n",
      "             ReLU-47          [-1, 128, 88, 88]               0\n",
      "       BasicBlock-48          [-1, 128, 88, 88]               0\n",
      "           Conv2d-49          [-1, 128, 88, 88]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 88, 88]             256\n",
      "             ReLU-51          [-1, 128, 88, 88]               0\n",
      "           Conv2d-52          [-1, 128, 88, 88]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 88, 88]             256\n",
      "             ReLU-54          [-1, 128, 88, 88]               0\n",
      "       BasicBlock-55          [-1, 128, 88, 88]               0\n",
      "           Conv2d-56          [-1, 256, 44, 44]         294,912\n",
      "      BatchNorm2d-57          [-1, 256, 44, 44]             512\n",
      "             ReLU-58          [-1, 256, 44, 44]               0\n",
      "           Conv2d-59          [-1, 256, 44, 44]         589,824\n",
      "      BatchNorm2d-60          [-1, 256, 44, 44]             512\n",
      "           Conv2d-61          [-1, 256, 44, 44]          32,768\n",
      "      BatchNorm2d-62          [-1, 256, 44, 44]             512\n",
      "             ReLU-63          [-1, 256, 44, 44]               0\n",
      "       BasicBlock-64          [-1, 256, 44, 44]               0\n",
      "           Conv2d-65          [-1, 256, 44, 44]         589,824\n",
      "      BatchNorm2d-66          [-1, 256, 44, 44]             512\n",
      "             ReLU-67          [-1, 256, 44, 44]               0\n",
      "           Conv2d-68          [-1, 256, 44, 44]         589,824\n",
      "      BatchNorm2d-69          [-1, 256, 44, 44]             512\n",
      "             ReLU-70          [-1, 256, 44, 44]               0\n",
      "       BasicBlock-71          [-1, 256, 44, 44]               0\n",
      "           Conv2d-72          [-1, 256, 44, 44]         589,824\n",
      "      BatchNorm2d-73          [-1, 256, 44, 44]             512\n",
      "             ReLU-74          [-1, 256, 44, 44]               0\n",
      "           Conv2d-75          [-1, 256, 44, 44]         589,824\n",
      "      BatchNorm2d-76          [-1, 256, 44, 44]             512\n",
      "             ReLU-77          [-1, 256, 44, 44]               0\n",
      "       BasicBlock-78          [-1, 256, 44, 44]               0\n",
      "           Conv2d-79          [-1, 256, 44, 44]         589,824\n",
      "      BatchNorm2d-80          [-1, 256, 44, 44]             512\n",
      "             ReLU-81          [-1, 256, 44, 44]               0\n",
      "           Conv2d-82          [-1, 256, 44, 44]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 44, 44]             512\n",
      "             ReLU-84          [-1, 256, 44, 44]               0\n",
      "       BasicBlock-85          [-1, 256, 44, 44]               0\n",
      "           Conv2d-86          [-1, 256, 44, 44]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 44, 44]             512\n",
      "             ReLU-88          [-1, 256, 44, 44]               0\n",
      "           Conv2d-89          [-1, 256, 44, 44]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 44, 44]             512\n",
      "             ReLU-91          [-1, 256, 44, 44]               0\n",
      "       BasicBlock-92          [-1, 256, 44, 44]               0\n",
      "           Conv2d-93          [-1, 256, 44, 44]         589,824\n",
      "      BatchNorm2d-94          [-1, 256, 44, 44]             512\n",
      "             ReLU-95          [-1, 256, 44, 44]               0\n",
      "           Conv2d-96          [-1, 256, 44, 44]         589,824\n",
      "      BatchNorm2d-97          [-1, 256, 44, 44]             512\n",
      "             ReLU-98          [-1, 256, 44, 44]               0\n",
      "       BasicBlock-99          [-1, 256, 44, 44]               0\n",
      "          Conv2d-100          [-1, 512, 22, 22]       1,179,648\n",
      "     BatchNorm2d-101          [-1, 512, 22, 22]           1,024\n",
      "            ReLU-102          [-1, 512, 22, 22]               0\n",
      "          Conv2d-103          [-1, 512, 22, 22]       2,359,296\n",
      "     BatchNorm2d-104          [-1, 512, 22, 22]           1,024\n",
      "          Conv2d-105          [-1, 512, 22, 22]         131,072\n",
      "     BatchNorm2d-106          [-1, 512, 22, 22]           1,024\n",
      "            ReLU-107          [-1, 512, 22, 22]               0\n",
      "      BasicBlock-108          [-1, 512, 22, 22]               0\n",
      "          Conv2d-109          [-1, 512, 22, 22]       2,359,296\n",
      "     BatchNorm2d-110          [-1, 512, 22, 22]           1,024\n",
      "            ReLU-111          [-1, 512, 22, 22]               0\n",
      "          Conv2d-112          [-1, 512, 22, 22]       2,359,296\n",
      "     BatchNorm2d-113          [-1, 512, 22, 22]           1,024\n",
      "            ReLU-114          [-1, 512, 22, 22]               0\n",
      "      BasicBlock-115          [-1, 512, 22, 22]               0\n",
      "          Conv2d-116          [-1, 512, 22, 22]       2,359,296\n",
      "     BatchNorm2d-117          [-1, 512, 22, 22]           1,024\n",
      "            ReLU-118          [-1, 512, 22, 22]               0\n",
      "          Conv2d-119          [-1, 512, 22, 22]       2,359,296\n",
      "     BatchNorm2d-120          [-1, 512, 22, 22]           1,024\n",
      "            ReLU-121          [-1, 512, 22, 22]               0\n",
      "      BasicBlock-122          [-1, 512, 22, 22]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                    [-1, 1]             513\n",
      "          Linear-125                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 21,286,211\n",
      "Trainable params: 21,286,211\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 5.61\n",
      "Forward/backward pass size (MB): 945.16\n",
      "Params size (MB): 81.20\n",
      "Estimated Total Size (MB): 1031.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = args.model\n",
    "model = create_model(model_name)\n",
    "summary(model.to('cuda'), input_size = (3, 700, 700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val = 100000000\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, betas = (0.5, 0.999))\n",
    "#torch.optim.SGD(model.parameters(), args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "#momentum = 0.9 \n",
    "#dataloader = train_loader\n",
    "scheduler = StepLR(optimizer, step_size = 1, gamma = 0.5)\n",
    "class_loss = class_loss()\n",
    "coord_loss = coord_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(datetime.datetime.now().today())\n",
    "time_info = today[5:7] +today[8:10] + '_' + today[11:13] + today[14:16]\n",
    "args.prefix = 'test' + time_info\n",
    "args.epochs = 50\n",
    "writer = SummaryWriter('runs/'+args.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for creating \n",
    "test_imlist, target_imlist =  gen_test_img_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Batch 10/128  Time 0.739s Data 0.574s || LOSS: CLS 0.069 X 577.18 Y 283.41 tot 860.655 | Current: 18:45:12\n",
      "Epoch[1] Batch 20/128  Time 0.464s Data 0.302s || LOSS: CLS 0.068 X 632.74 Y 328.19 tot 960.996 | Current: 18:45:14\n",
      "Epoch[1] Batch 30/128  Time 0.366s Data 0.206s || LOSS: CLS 0.073 X 571.85 Y 290.99 tot 862.908 | Current: 18:45:15\n",
      "Epoch[1] Batch 40/128  Time 0.316s Data 0.157s || LOSS: CLS 0.068 X 520.15 Y 266.08 tot 786.296 | Current: 18:45:17\n",
      "Epoch[1] Batch 50/128  Time 0.285s Data 0.127s || LOSS: CLS 0.065 X 548.89 Y 267.43 tot 816.386 | Current: 18:45:18\n",
      "Epoch[1] Batch 60/128  Time 0.265s Data 0.107s || LOSS: CLS 0.063 X 541.87 Y 256.34 tot 798.275 | Current: 18:45:20\n",
      "Epoch[1] Batch 70/128  Time 0.251s Data 0.092s || LOSS: CLS 0.061 X 500.13 Y 238.84 tot 739.030 | Current: 18:45:22\n",
      "Epoch[1] Batch 80/128  Time 0.240s Data 0.081s || LOSS: CLS 0.060 X 474.20 Y 227.69 tot 701.957 | Current: 18:45:23\n",
      "Epoch[1] Batch 90/128  Time 0.231s Data 0.073s || LOSS: CLS 0.059 X 483.04 Y 227.13 tot 710.227 | Current: 18:45:25\n",
      "Epoch[1] Batch 100/128  Time 0.224s Data 0.066s || LOSS: CLS 0.061 X 466.79 Y 225.50 tot 692.353 | Current: 18:45:26\n",
      "Epoch[1] Batch 110/128  Time 0.219s Data 0.060s || LOSS: CLS 0.063 X 481.24 Y 222.27 tot 703.572 | Current: 18:45:28\n",
      "Epoch[1] Batch 120/128  Time 0.214s Data 0.056s || LOSS: CLS 0.060 X 502.49 Y 240.10 tot 742.650 | Current: 18:45:30\n",
      "Epoch[1] Batch 10/15  Time 0.827s || LOSS: CLS 0.023 X 493.59 Y 277.62 tot 771.230 | Current: 18:45:40\n",
      "writing test img with step 2\n",
      "Epoch[2] Batch 10/128  Time 0.753s Data 0.590s || LOSS: CLS 0.045 X 370.70 Y 153.46 tot 524.200 | Current: 18:45:52\n",
      "Epoch[2] Batch 20/128  Time 0.469s Data 0.311s || LOSS: CLS 0.037 X 499.68 Y 248.65 tot 748.360 | Current: 18:45:53\n",
      "Epoch[2] Batch 30/128  Time 0.369s Data 0.212s || LOSS: CLS 0.034 X 376.97 Y 191.25 tot 568.245 | Current: 18:45:55\n",
      "Epoch[2] Batch 40/128  Time 0.318s Data 0.161s || LOSS: CLS 0.035 X 366.71 Y 176.23 tot 542.977 | Current: 18:45:56\n",
      "Epoch[2] Batch 50/128  Time 0.287s Data 0.130s || LOSS: CLS 0.034 X 450.97 Y 222.97 tot 673.972 | Current: 18:45:58\n",
      "Epoch[2] Batch 60/128  Time 0.266s Data 0.109s || LOSS: CLS 0.032 X 469.00 Y 236.03 tot 705.055 | Current: 18:46:00\n",
      "Epoch[2] Batch 70/128  Time 0.251s Data 0.095s || LOSS: CLS 0.034 X 467.12 Y 224.14 tot 691.291 | Current: 18:46:01\n",
      "Epoch[2] Batch 80/128  Time 0.240s Data 0.083s || LOSS: CLS 0.032 X 447.85 Y 205.44 tot 653.327 | Current: 18:46:03\n",
      "Epoch[2] Batch 90/128  Time 0.231s Data 0.075s || LOSS: CLS 0.032 X 434.63 Y 204.73 tot 639.391 | Current: 18:46:04\n",
      "Epoch[2] Batch 100/128  Time 0.224s Data 0.068s || LOSS: CLS 0.031 X 409.75 Y 191.95 tot 601.727 | Current: 18:46:06\n",
      "Epoch[2] Batch 110/128  Time 0.218s Data 0.062s || LOSS: CLS 0.032 X 410.57 Y 201.35 tot 611.945 | Current: 18:46:08\n",
      "Epoch[2] Batch 120/128  Time 0.213s Data 0.057s || LOSS: CLS 0.031 X 407.25 Y 200.76 tot 608.045 | Current: 18:46:09\n",
      "Epoch[2] Batch 10/15  Time 0.815s || LOSS: CLS 0.145 X 2374.68 Y 1392.66 tot 3767.485 | Current: 18:46:20\n",
      "writing test img with step 3\n",
      "Epoch[3] Batch 10/128  Time 0.727s Data 0.572s || LOSS: CLS 0.017 X 182.06 Y 122.00 tot 304.076 | Current: 18:46:31\n",
      "Epoch[3] Batch 20/128  Time 0.454s Data 0.301s || LOSS: CLS 0.025 X 307.05 Y 133.32 tot 440.398 | Current: 18:46:32\n",
      "Epoch[3] Batch 30/128  Time 0.357s Data 0.205s || LOSS: CLS 0.026 X 422.12 Y 181.96 tot 604.111 | Current: 18:46:34\n",
      "Epoch[3] Batch 40/128  Time 0.308s Data 0.156s || LOSS: CLS 0.024 X 427.81 Y 201.59 tot 629.422 | Current: 18:46:36\n",
      "Epoch[3] Batch 50/128  Time 0.278s Data 0.126s || LOSS: CLS 0.024 X 431.97 Y 222.00 tot 653.995 | Current: 18:46:37\n",
      "Epoch[3] Batch 60/128  Time 0.258s Data 0.106s || LOSS: CLS 0.024 X 437.82 Y 222.51 tot 660.348 | Current: 18:46:39\n",
      "Epoch[3] Batch 70/128  Time 0.243s Data 0.092s || LOSS: CLS 0.027 X 463.88 Y 214.21 tot 678.123 | Current: 18:46:40\n",
      "Epoch[3] Batch 80/128  Time 0.232s Data 0.081s || LOSS: CLS 0.030 X 490.74 Y 229.41 tot 720.178 | Current: 18:46:42\n",
      "Epoch[3] Batch 90/128  Time 0.224s Data 0.072s || LOSS: CLS 0.031 X 469.34 Y 221.58 tot 690.950 | Current: 18:46:43\n",
      "Epoch[3] Batch 100/128  Time 0.217s Data 0.066s || LOSS: CLS 0.031 X 478.00 Y 217.24 tot 695.271 | Current: 18:46:45\n",
      "Epoch[3] Batch 110/128  Time 0.212s Data 0.060s || LOSS: CLS 0.031 X 464.99 Y 213.19 tot 678.204 | Current: 18:46:46\n",
      "Epoch[3] Batch 120/128  Time 0.207s Data 0.055s || LOSS: CLS 0.030 X 441.95 Y 200.74 tot 642.720 | Current: 18:46:48\n",
      "Epoch[3] Batch 10/15  Time 0.810s || LOSS: CLS 0.013 X 495.26 Y 278.12 tot 773.390 | Current: 18:46:58\n",
      "writing test img with step 4\n",
      "Epoch[4] Batch 10/128  Time 0.785s Data 0.619s || LOSS: CLS 0.056 X 731.38 Y 281.47 tot 1012.906 | Current: 18:47:10\n",
      "Epoch[4] Batch 20/128  Time 0.492s Data 0.326s || LOSS: CLS 0.057 X 610.54 Y 262.36 tot 872.956 | Current: 18:47:12\n",
      "Epoch[4] Batch 30/128  Time 0.387s Data 0.222s || LOSS: CLS 0.043 X 515.46 Y 254.54 tot 770.047 | Current: 18:47:13\n",
      "Epoch[4] Batch 40/128  Time 0.333s Data 0.169s || LOSS: CLS 0.035 X 483.89 Y 228.35 tot 712.279 | Current: 18:47:15\n",
      "Epoch[4] Batch 50/128  Time 0.300s Data 0.137s || LOSS: CLS 0.031 X 410.22 Y 190.88 tot 601.126 | Current: 18:47:17\n",
      "Epoch[4] Batch 60/128  Time 0.278s Data 0.115s || LOSS: CLS 0.030 X 453.50 Y 212.36 tot 665.887 | Current: 18:47:18\n",
      "Epoch[4] Batch 70/128  Time 0.262s Data 0.099s || LOSS: CLS 0.027 X 447.75 Y 223.76 tot 671.541 | Current: 18:47:20\n",
      "Epoch[4] Batch 80/128  Time 0.251s Data 0.087s || LOSS: CLS 0.027 X 447.40 Y 216.81 tot 664.239 | Current: 18:47:22\n",
      "Epoch[4] Batch 90/128  Time 0.241s Data 0.078s || LOSS: CLS 0.026 X 432.42 Y 205.92 tot 638.361 | Current: 18:47:23\n",
      "Epoch[4] Batch 100/128  Time 0.234s Data 0.071s || LOSS: CLS 0.024 X 404.14 Y 195.15 tot 599.317 | Current: 18:47:25\n",
      "Epoch[4] Batch 110/128  Time 0.228s Data 0.065s || LOSS: CLS 0.023 X 374.84 Y 184.85 tot 559.707 | Current: 18:47:27\n",
      "Epoch[4] Batch 120/128  Time 0.224s Data 0.060s || LOSS: CLS 0.022 X 403.58 Y 188.39 tot 591.985 | Current: 18:47:28\n",
      "Epoch[4] Batch 10/15  Time 0.818s || LOSS: CLS 0.005 X 370.18 Y 209.78 tot 579.965 | Current: 18:47:39\n",
      "writing test img with step 5\n",
      "Epoch[5] Batch 10/128  Time 0.737s Data 0.576s || LOSS: CLS 0.006 X 459.39 Y 142.44 tot 601.839 | Current: 18:47:50\n",
      "Epoch[5] Batch 20/128  Time 0.467s Data 0.303s || LOSS: CLS 0.013 X 518.68 Y 232.21 tot 750.907 | Current: 18:47:52\n",
      "Epoch[5] Batch 30/128  Time 0.370s Data 0.207s || LOSS: CLS 0.028 X 449.91 Y 198.97 tot 648.914 | Current: 18:47:54\n",
      "Epoch[5] Batch 40/128  Time 0.320s Data 0.157s || LOSS: CLS 0.024 X 424.13 Y 186.95 tot 611.104 | Current: 18:47:55\n",
      "Epoch[5] Batch 50/128  Time 0.289s Data 0.127s || LOSS: CLS 0.026 X 417.69 Y 182.22 tot 599.937 | Current: 18:47:57\n",
      "Epoch[5] Batch 60/128  Time 0.268s Data 0.107s || LOSS: CLS 0.023 X 411.94 Y 191.30 tot 603.255 | Current: 18:47:59\n",
      "Epoch[5] Batch 70/128  Time 0.253s Data 0.093s || LOSS: CLS 0.024 X 404.43 Y 183.24 tot 587.700 | Current: 18:48:00\n",
      "Epoch[5] Batch 80/128  Time 0.242s Data 0.082s || LOSS: CLS 0.021 X 429.66 Y 199.96 tot 629.643 | Current: 18:48:02\n",
      "Epoch[5] Batch 90/128  Time 0.233s Data 0.073s || LOSS: CLS 0.021 X 431.95 Y 192.32 tot 624.291 | Current: 18:48:03\n",
      "Epoch[5] Batch 100/128  Time 0.226s Data 0.066s || LOSS: CLS 0.019 X 424.62 Y 189.45 tot 614.094 | Current: 18:48:05\n",
      "Epoch[5] Batch 110/128  Time 0.220s Data 0.061s || LOSS: CLS 0.018 X 410.73 Y 185.22 tot 595.965 | Current: 18:48:07\n",
      "Epoch[5] Batch 120/128  Time 0.215s Data 0.056s || LOSS: CLS 0.017 X 399.10 Y 188.10 tot 587.213 | Current: 18:48:08\n",
      "Epoch[5] Batch 10/15  Time 0.829s || LOSS: CLS 0.011 X 513.58 Y 272.82 tot 786.414 | Current: 18:48:19\n",
      "writing test img with step 6\n",
      "Epoch[6] Batch 10/128  Time 0.754s Data 0.586s || LOSS: CLS 0.008 X 538.72 Y 178.12 tot 716.855 | Current: 18:48:30\n",
      "Epoch[6] Batch 20/128  Time 0.474s Data 0.309s || LOSS: CLS 0.013 X 431.90 Y 161.29 tot 593.195 | Current: 18:48:32\n",
      "Epoch[6] Batch 30/128  Time 0.376s Data 0.211s || LOSS: CLS 0.012 X 443.02 Y 169.13 tot 612.154 | Current: 18:48:34\n",
      "Epoch[6] Batch 40/128  Time 0.324s Data 0.160s || LOSS: CLS 0.015 X 453.86 Y 206.23 tot 660.109 | Current: 18:48:35\n",
      "Epoch[6] Batch 50/128  Time 0.294s Data 0.130s || LOSS: CLS 0.014 X 416.38 Y 211.77 tot 628.164 | Current: 18:48:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6] Batch 60/128  Time 0.273s Data 0.109s || LOSS: CLS 0.018 X 413.29 Y 198.70 tot 612.010 | Current: 18:48:39\n",
      "Epoch[6] Batch 70/128  Time 0.257s Data 0.094s || LOSS: CLS 0.019 X 412.33 Y 192.91 tot 605.263 | Current: 18:48:40\n",
      "Epoch[6] Batch 80/128  Time 0.246s Data 0.083s || LOSS: CLS 0.018 X 406.22 Y 195.44 tot 601.687 | Current: 18:48:42\n",
      "Epoch[6] Batch 90/128  Time 0.237s Data 0.074s || LOSS: CLS 0.017 X 395.15 Y 193.37 tot 588.541 | Current: 18:48:44\n",
      "Epoch[6] Batch 100/128  Time 0.231s Data 0.067s || LOSS: CLS 0.016 X 374.91 Y 181.18 tot 556.107 | Current: 18:48:45\n",
      "Epoch[6] Batch 110/128  Time 0.225s Data 0.062s || LOSS: CLS 0.015 X 392.22 Y 184.62 tot 576.860 | Current: 18:48:47\n",
      "Epoch[6] Batch 120/128  Time 0.221s Data 0.057s || LOSS: CLS 0.015 X 376.23 Y 173.26 tot 549.502 | Current: 18:48:49\n",
      "Epoch[6] Batch 10/15  Time 0.820s || LOSS: CLS 0.003 X 362.35 Y 178.64 tot 540.998 | Current: 18:48:59\n",
      "writing test img with step 7\n",
      "Epoch[7] Batch 10/128  Time 0.744s Data 0.580s || LOSS: CLS 0.007 X 284.31 Y 129.67 tot 413.991 | Current: 18:49:11\n",
      "Epoch[7] Batch 20/128  Time 0.466s Data 0.306s || LOSS: CLS 0.005 X 170.08 Y 120.32 tot 290.406 | Current: 18:49:12\n",
      "Epoch[7] Batch 30/128  Time 0.369s Data 0.208s || LOSS: CLS 0.007 X 244.67 Y 142.71 tot 387.385 | Current: 18:49:14\n",
      "Epoch[7] Batch 40/128  Time 0.321s Data 0.159s || LOSS: CLS 0.007 X 278.27 Y 139.24 tot 417.517 | Current: 18:49:16\n",
      "Epoch[7] Batch 50/128  Time 0.290s Data 0.128s || LOSS: CLS 0.008 X 304.25 Y 163.74 tot 467.997 | Current: 18:49:17\n",
      "Epoch[7] Batch 60/128  Time 0.269s Data 0.108s || LOSS: CLS 0.007 X 331.78 Y 163.74 tot 495.529 | Current: 18:49:19\n",
      "Epoch[7] Batch 70/128  Time 0.254s Data 0.093s || LOSS: CLS 0.008 X 339.15 Y 171.81 tot 510.977 | Current: 18:49:21\n",
      "Epoch[7] Batch 80/128  Time 0.243s Data 0.082s || LOSS: CLS 0.008 X 324.88 Y 160.42 tot 485.313 | Current: 18:49:22\n",
      "Epoch[7] Batch 90/128  Time 0.234s Data 0.074s || LOSS: CLS 0.007 X 339.03 Y 172.80 tot 511.839 | Current: 18:49:24\n",
      "Epoch[7] Batch 100/128  Time 0.227s Data 0.067s || LOSS: CLS 0.007 X 327.72 Y 163.80 tot 491.531 | Current: 18:49:25\n",
      "Epoch[7] Batch 110/128  Time 0.221s Data 0.061s || LOSS: CLS 0.007 X 334.00 Y 168.69 tot 502.693 | Current: 18:49:27\n",
      "Epoch[7] Batch 120/128  Time 0.217s Data 0.056s || LOSS: CLS 0.008 X 332.35 Y 172.86 tot 505.219 | Current: 18:49:29\n",
      "Epoch[7] Batch 10/15  Time 0.799s || LOSS: CLS 0.001 X 430.90 Y 238.02 tot 668.920 | Current: 18:49:39\n",
      "writing test img with step 8\n",
      "Epoch[8] Batch 10/128  Time 0.756s Data 0.596s || LOSS: CLS 0.003 X 162.87 Y 130.15 tot 293.030 | Current: 18:49:51\n",
      "Epoch[8] Batch 20/128  Time 0.477s Data 0.314s || LOSS: CLS 0.004 X 380.38 Y 192.31 tot 572.690 | Current: 18:49:52\n",
      "Epoch[8] Batch 30/128  Time 0.376s Data 0.214s || LOSS: CLS 0.006 X 321.49 Y 171.46 tot 492.950 | Current: 18:49:54\n",
      "Epoch[8] Batch 40/128  Time 0.325s Data 0.163s || LOSS: CLS 0.007 X 387.10 Y 215.14 tot 602.242 | Current: 18:49:56\n",
      "Epoch[8] Batch 50/128  Time 0.293s Data 0.132s || LOSS: CLS 0.009 X 382.61 Y 205.58 tot 588.194 | Current: 18:49:57\n",
      "Epoch[8] Batch 60/128  Time 0.272s Data 0.111s || LOSS: CLS 0.008 X 370.99 Y 202.86 tot 573.860 | Current: 18:49:59\n",
      "Epoch[8] Batch 70/128  Time 0.256s Data 0.096s || LOSS: CLS 0.008 X 359.51 Y 186.25 tot 545.773 | Current: 18:50:01\n",
      "Epoch[8] Batch 80/128  Time 0.245s Data 0.084s || LOSS: CLS 0.007 X 340.22 Y 175.80 tot 516.026 | Current: 18:50:02\n",
      "Epoch[8] Batch 90/128  Time 0.236s Data 0.075s || LOSS: CLS 0.007 X 332.01 Y 171.02 tot 503.029 | Current: 18:50:04\n",
      "Epoch[8] Batch 100/128  Time 0.229s Data 0.068s || LOSS: CLS 0.007 X 321.78 Y 167.99 tot 489.781 | Current: 18:50:06\n",
      "Epoch[8] Batch 110/128  Time 0.223s Data 0.063s || LOSS: CLS 0.007 X 309.54 Y 165.24 tot 474.790 | Current: 18:50:07\n",
      "Epoch[8] Batch 120/128  Time 0.218s Data 0.058s || LOSS: CLS 0.008 X 306.70 Y 169.50 tot 476.215 | Current: 18:50:09\n",
      "Epoch[8] Batch 10/15  Time 0.795s || LOSS: CLS 2.972 X 9132.77 Y 3547.01 tot 12682.751 | Current: 18:50:19\n",
      "writing test img with step 9\n",
      "Epoch[9] Batch 10/128  Time 0.753s Data 0.590s || LOSS: CLS 0.021 X 235.94 Y 83.67 tot 319.626 | Current: 18:50:31\n",
      "Epoch[9] Batch 20/128  Time 0.473s Data 0.311s || LOSS: CLS 0.013 X 424.27 Y 213.14 tot 637.422 | Current: 18:50:32\n",
      "Epoch[9] Batch 30/128  Time 0.373s Data 0.212s || LOSS: CLS 0.009 X 497.63 Y 237.13 tot 734.773 | Current: 18:50:34\n",
      "Epoch[9] Batch 40/128  Time 0.323s Data 0.161s || LOSS: CLS 0.009 X 534.93 Y 265.68 tot 800.617 | Current: 18:50:36\n",
      "Epoch[9] Batch 50/128  Time 0.293s Data 0.130s || LOSS: CLS 0.009 X 462.73 Y 233.55 tot 696.288 | Current: 18:50:37\n",
      "Epoch[9] Batch 60/128  Time 0.271s Data 0.110s || LOSS: CLS 0.011 X 421.46 Y 211.31 tot 632.784 | Current: 18:50:39\n",
      "Epoch[9] Batch 70/128  Time 0.256s Data 0.095s || LOSS: CLS 0.010 X 445.66 Y 207.73 tot 653.406 | Current: 18:50:40\n",
      "Epoch[9] Batch 80/128  Time 0.245s Data 0.084s || LOSS: CLS 0.015 X 418.37 Y 197.50 tot 615.886 | Current: 18:50:42\n",
      "Epoch[9] Batch 90/128  Time 0.236s Data 0.075s || LOSS: CLS 0.013 X 394.89 Y 199.93 tot 594.839 | Current: 18:50:44\n",
      "Epoch[9] Batch 100/128  Time 0.229s Data 0.068s || LOSS: CLS 0.012 X 358.32 Y 182.01 tot 540.345 | Current: 18:50:45\n",
      "Epoch[9] Batch 110/128  Time 0.223s Data 0.062s || LOSS: CLS 0.012 X 348.63 Y 176.11 tot 524.749 | Current: 18:50:47\n",
      "Epoch[9] Batch 120/128  Time 0.218s Data 0.057s || LOSS: CLS 0.011 X 322.51 Y 163.15 tot 485.668 | Current: 18:50:49\n",
      "Epoch[9] Batch 10/15  Time 0.784s || LOSS: CLS 0.002 X 218.37 Y 143.26 tot 361.632 | Current: 18:50:59\n",
      "writing test img with step 10\n",
      "Epoch[10] Batch 10/128  Time 0.766s Data 0.602s || LOSS: CLS 0.003 X 299.34 Y 194.46 tot 493.797 | Current: 18:51:10\n",
      "Epoch[10] Batch 20/128  Time 0.478s Data 0.317s || LOSS: CLS 0.004 X 319.82 Y 156.73 tot 476.557 | Current: 18:51:12\n",
      "Epoch[10] Batch 30/128  Time 0.376s Data 0.216s || LOSS: CLS 0.004 X 282.34 Y 162.14 tot 444.486 | Current: 18:51:13\n",
      "Epoch[10] Batch 40/128  Time 0.323s Data 0.164s || LOSS: CLS 0.003 X 293.78 Y 154.88 tot 448.666 | Current: 18:51:15\n",
      "Epoch[10] Batch 50/128  Time 0.292s Data 0.133s || LOSS: CLS 0.013 X 301.85 Y 150.33 tot 452.191 | Current: 18:51:17\n",
      "Epoch[10] Batch 60/128  Time 0.272s Data 0.112s || LOSS: CLS 0.013 X 264.38 Y 136.11 tot 400.504 | Current: 18:51:18\n",
      "Epoch[10] Batch 70/128  Time 0.258s Data 0.097s || LOSS: CLS 0.017 X 272.91 Y 145.38 tot 418.313 | Current: 18:51:20\n",
      "Epoch[10] Batch 80/128  Time 0.246s Data 0.085s || LOSS: CLS 0.016 X 304.61 Y 157.34 tot 461.966 | Current: 18:51:22\n",
      "Epoch[10] Batch 90/128  Time 0.237s Data 0.076s || LOSS: CLS 0.015 X 306.63 Y 162.44 tot 469.090 | Current: 18:51:23\n",
      "Epoch[10] Batch 100/128  Time 0.230s Data 0.069s || LOSS: CLS 0.015 X 330.84 Y 177.21 tot 508.068 | Current: 18:51:25\n",
      "Epoch[10] Batch 110/128  Time 0.224s Data 0.063s || LOSS: CLS 0.014 X 324.96 Y 169.19 tot 494.159 | Current: 18:51:27\n",
      "Epoch[10] Batch 120/128  Time 0.219s Data 0.058s || LOSS: CLS 0.014 X 332.17 Y 171.62 tot 503.803 | Current: 18:51:28\n",
      "Epoch[10] Batch 10/15  Time 0.799s || LOSS: CLS 0.003 X 240.08 Y 130.34 tot 370.423 | Current: 18:51:38\n",
      "writing test img with step 11\n",
      "Epoch[11] Batch 10/128  Time 0.752s Data 0.588s || LOSS: CLS 0.005 X 521.77 Y 239.12 tot 760.897 | Current: 18:51:50\n",
      "Epoch[11] Batch 20/128  Time 0.471s Data 0.310s || LOSS: CLS 0.005 X 358.60 Y 167.01 tot 525.617 | Current: 18:51:51\n",
      "Epoch[11] Batch 30/128  Time 0.371s Data 0.211s || LOSS: CLS 0.015 X 378.11 Y 162.91 tot 541.040 | Current: 18:51:53\n",
      "Epoch[11] Batch 40/128  Time 0.320s Data 0.161s || LOSS: CLS 0.013 X 377.98 Y 185.11 tot 563.096 | Current: 18:51:55\n",
      "Epoch[11] Batch 50/128  Time 0.288s Data 0.130s || LOSS: CLS 0.179 X 806.25 Y 320.90 tot 1127.331 | Current: 18:51:56\n",
      "Epoch[11] Batch 60/128  Time 0.267s Data 0.109s || LOSS: CLS 0.349 X 1202.60 Y 334.22 tot 1537.168 | Current: 18:51:58\n",
      "Epoch[11] Batch 70/128  Time 0.252s Data 0.094s || LOSS: CLS 0.387 X 1315.48 Y 337.55 tot 1653.421 | Current: 18:51:59\n",
      "Epoch[11] Batch 80/128  Time 0.243s Data 0.083s || LOSS: CLS 0.376 X 1316.27 Y 340.91 tot 1657.560 | Current: 18:52:01\n",
      "Epoch[11] Batch 90/128  Time 0.234s Data 0.075s || LOSS: CLS 0.360 X 1250.79 Y 328.35 tot 1579.504 | Current: 18:52:03\n",
      "Epoch[11] Batch 100/128  Time 0.227s Data 0.068s || LOSS: CLS 0.347 X 1206.05 Y 324.93 tot 1531.321 | Current: 18:52:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[11] Batch 110/128  Time 0.221s Data 0.062s || LOSS: CLS 0.331 X 1151.24 Y 315.48 tot 1467.048 | Current: 18:52:06\n",
      "Epoch[11] Batch 120/128  Time 0.216s Data 0.057s || LOSS: CLS 0.321 X 1108.27 Y 307.90 tot 1416.487 | Current: 18:52:08\n",
      "Epoch[11] Batch 10/15  Time 0.822s || LOSS: CLS 1.900 X 8553.47 Y 2941.41 tot 11496.779 | Current: 18:52:18\n",
      "writing test img with step 12\n",
      "Epoch[12] Batch 10/128  Time 0.746s Data 0.583s || LOSS: CLS 0.136 X 582.63 Y 171.65 tot 754.422 | Current: 18:52:30\n",
      "Epoch[12] Batch 20/128  Time 0.467s Data 0.307s || LOSS: CLS 0.111 X 696.58 Y 288.41 tot 985.102 | Current: 18:52:31\n",
      "Epoch[12] Batch 30/128  Time 0.367s Data 0.210s || LOSS: CLS 0.091 X 560.94 Y 248.69 tot 809.722 | Current: 18:52:33\n",
      "Epoch[12] Batch 40/128  Time 0.317s Data 0.159s || LOSS: CLS 0.080 X 462.18 Y 209.64 tot 671.896 | Current: 18:52:34\n",
      "Epoch[12] Batch 50/128  Time 0.286s Data 0.129s || LOSS: CLS 0.079 X 435.94 Y 197.52 tot 633.547 | Current: 18:52:36\n",
      "Epoch[12] Batch 60/128  Time 0.266s Data 0.108s || LOSS: CLS 0.076 X 468.07 Y 200.83 tot 668.975 | Current: 18:52:38\n",
      "Epoch[12] Batch 70/128  Time 0.251s Data 0.094s || LOSS: CLS 0.074 X 492.37 Y 220.48 tot 712.922 | Current: 18:52:39\n",
      "Epoch[12] Batch 80/128  Time 0.240s Data 0.083s || LOSS: CLS 0.074 X 472.40 Y 213.86 tot 686.338 | Current: 18:52:41\n",
      "Epoch[12] Batch 90/128  Time 0.231s Data 0.074s || LOSS: CLS 0.069 X 480.18 Y 207.53 tot 687.769 | Current: 18:52:42\n",
      "Epoch[12] Batch 100/128  Time 0.225s Data 0.067s || LOSS: CLS 0.067 X 490.48 Y 207.72 tot 698.259 | Current: 18:52:44\n",
      "Epoch[12] Batch 110/128  Time 0.219s Data 0.061s || LOSS: CLS 0.063 X 489.38 Y 208.80 tot 698.240 | Current: 18:52:46\n",
      "Epoch[12] Batch 120/128  Time 0.214s Data 0.057s || LOSS: CLS 0.060 X 478.37 Y 201.72 tot 680.155 | Current: 18:52:47\n",
      "Epoch[12] Batch 10/15  Time 0.799s || LOSS: CLS 0.028 X 499.17 Y 304.20 tot 803.395 | Current: 18:52:58\n",
      "writing test img with step 13\n",
      "Epoch[13] Batch 10/128  Time 0.722s Data 0.563s || LOSS: CLS 0.024 X 414.10 Y 158.15 tot 572.269 | Current: 18:53:09\n",
      "Epoch[13] Batch 20/128  Time 0.454s Data 0.297s || LOSS: CLS 0.028 X 382.80 Y 149.76 tot 532.589 | Current: 18:53:10\n",
      "Epoch[13] Batch 30/128  Time 0.359s Data 0.202s || LOSS: CLS 0.043 X 505.36 Y 220.89 tot 726.299 | Current: 18:53:12\n",
      "Epoch[13] Batch 40/128  Time 0.311s Data 0.154s || LOSS: CLS 0.038 X 471.02 Y 195.02 tot 666.077 | Current: 18:53:14\n",
      "Epoch[13] Batch 50/128  Time 0.282s Data 0.124s || LOSS: CLS 0.034 X 462.03 Y 190.59 tot 652.656 | Current: 18:53:15\n",
      "Epoch[13] Batch 60/128  Time 0.262s Data 0.105s || LOSS: CLS 0.030 X 429.22 Y 186.95 tot 616.197 | Current: 18:53:17\n",
      "Epoch[13] Batch 70/128  Time 0.248s Data 0.091s || LOSS: CLS 0.029 X 382.11 Y 166.15 tot 548.291 | Current: 18:53:18\n",
      "Epoch[13] Batch 80/128  Time 0.238s Data 0.080s || LOSS: CLS 0.027 X 346.59 Y 150.61 tot 497.225 | Current: 18:53:20\n",
      "Epoch[13] Batch 90/128  Time 0.230s Data 0.072s || LOSS: CLS 0.025 X 342.05 Y 165.24 tot 507.313 | Current: 18:53:22\n",
      "Epoch[13] Batch 100/128  Time 0.223s Data 0.065s || LOSS: CLS 0.025 X 365.95 Y 173.95 tot 539.927 | Current: 18:53:23\n",
      "Epoch[13] Batch 110/128  Time 0.218s Data 0.059s || LOSS: CLS 0.024 X 361.65 Y 176.04 tot 537.718 | Current: 18:53:25\n",
      "Epoch[13] Batch 120/128  Time 0.213s Data 0.055s || LOSS: CLS 0.022 X 361.57 Y 177.68 tot 539.274 | Current: 18:53:27\n",
      "Epoch[13] Batch 10/15  Time 0.840s || LOSS: CLS 1.451 X 2805.13 Y 3859.94 tot 6666.523 | Current: 18:53:37\n",
      "writing test img with step 14\n",
      "Epoch[14] Batch 10/128  Time 0.740s Data 0.583s || LOSS: CLS 0.074 X 528.25 Y 244.74 tot 773.060 | Current: 18:53:49\n",
      "Epoch[14] Batch 20/128  Time 0.465s Data 0.307s || LOSS: CLS 0.045 X 455.97 Y 200.11 tot 656.125 | Current: 18:53:51\n",
      "Epoch[14] Batch 30/128  Time 0.368s Data 0.210s || LOSS: CLS 0.036 X 384.02 Y 185.55 tot 569.609 | Current: 18:53:52\n",
      "Epoch[14] Batch 40/128  Time 0.319s Data 0.160s || LOSS: CLS 0.029 X 341.38 Y 162.16 tot 503.573 | Current: 18:53:54\n",
      "Epoch[14] Batch 50/128  Time 0.290s Data 0.129s || LOSS: CLS 0.025 X 345.14 Y 165.54 tot 510.711 | Current: 18:53:56\n",
      "Epoch[14] Batch 60/128  Time 0.270s Data 0.109s || LOSS: CLS 0.023 X 343.86 Y 171.20 tot 515.079 | Current: 18:53:57\n",
      "Epoch[14] Batch 70/128  Time 0.256s Data 0.094s || LOSS: CLS 0.021 X 350.85 Y 167.69 tot 518.568 | Current: 18:53:59\n",
      "Epoch[14] Batch 80/128  Time 0.245s Data 0.083s || LOSS: CLS 0.019 X 366.09 Y 181.28 tot 547.394 | Current: 18:54:01\n",
      "Epoch[14] Batch 90/128  Time 0.236s Data 0.074s || LOSS: CLS 0.018 X 347.27 Y 170.33 tot 517.613 | Current: 18:54:02\n",
      "Epoch[14] Batch 100/128  Time 0.229s Data 0.067s || LOSS: CLS 0.017 X 372.59 Y 178.50 tot 551.107 | Current: 18:54:04\n",
      "Epoch[14] Batch 110/128  Time 0.223s Data 0.061s || LOSS: CLS 0.016 X 347.97 Y 167.70 tot 515.689 | Current: 18:54:05\n",
      "Epoch[14] Batch 120/128  Time 0.218s Data 0.057s || LOSS: CLS 0.017 X 382.02 Y 184.20 tot 566.241 | Current: 18:54:07\n",
      "Epoch[14] Batch 10/15  Time 0.797s || LOSS: CLS 0.004 X 396.40 Y 310.05 tot 706.450 | Current: 18:54:17\n",
      "writing test img with step 15\n",
      "Epoch[15] Batch 10/128  Time 0.751s Data 0.588s || LOSS: CLS 0.013 X 310.09 Y 184.62 tot 494.724 | Current: 18:54:29\n",
      "Epoch[15] Batch 20/128  Time 0.471s Data 0.310s || LOSS: CLS 0.009 X 280.09 Y 186.24 tot 466.343 | Current: 18:54:30\n",
      "Epoch[15] Batch 30/128  Time 0.374s Data 0.211s || LOSS: CLS 0.008 X 328.43 Y 196.07 tot 524.515 | Current: 18:54:32\n",
      "Epoch[15] Batch 40/128  Time 0.322s Data 0.161s || LOSS: CLS 0.008 X 339.04 Y 184.06 tot 523.108 | Current: 18:54:34\n",
      "Epoch[15] Batch 50/128  Time 0.292s Data 0.130s || LOSS: CLS 0.008 X 347.42 Y 186.24 tot 533.667 | Current: 18:54:35\n",
      "Epoch[15] Batch 60/128  Time 0.271s Data 0.109s || LOSS: CLS 0.009 X 329.96 Y 171.57 tot 501.533 | Current: 18:54:37\n",
      "Epoch[15] Batch 70/128  Time 0.256s Data 0.095s || LOSS: CLS 0.009 X 354.16 Y 188.56 tot 542.731 | Current: 18:54:39\n",
      "Epoch[15] Batch 80/128  Time 0.244s Data 0.083s || LOSS: CLS 0.009 X 339.88 Y 178.09 tot 517.987 | Current: 18:54:40\n",
      "Epoch[15] Batch 90/128  Time 0.235s Data 0.075s || LOSS: CLS 0.011 X 330.83 Y 169.92 tot 500.767 | Current: 18:54:42\n",
      "Epoch[15] Batch 100/128  Time 0.227s Data 0.068s || LOSS: CLS 0.011 X 321.46 Y 158.98 tot 480.446 | Current: 18:54:43\n",
      "Epoch[15] Batch 110/128  Time 0.221s Data 0.062s || LOSS: CLS 0.010 X 327.58 Y 162.68 tot 490.273 | Current: 18:54:45\n",
      "Epoch[15] Batch 120/128  Time 0.216s Data 0.057s || LOSS: CLS 0.010 X 340.90 Y 175.14 tot 516.049 | Current: 18:54:47\n",
      "Epoch[15] Batch 10/15  Time 0.790s || LOSS: CLS 1.060 X 3522.63 Y 3340.95 tot 6864.643 | Current: 18:54:57\n",
      "writing test img with step 16\n",
      "Epoch[16] Batch 10/128  Time 0.729s Data 0.565s || LOSS: CLS 0.003 X 218.25 Y 118.92 tot 337.180 | Current: 18:55:08\n",
      "Epoch[16] Batch 20/128  Time 0.461s Data 0.298s || LOSS: CLS 0.004 X 171.83 Y 102.86 tot 274.701 | Current: 18:55:10\n",
      "Epoch[16] Batch 30/128  Time 0.367s Data 0.203s || LOSS: CLS 0.006 X 211.42 Y 93.22 tot 304.647 | Current: 18:55:12\n",
      "Epoch[16] Batch 40/128  Time 0.317s Data 0.155s || LOSS: CLS 0.006 X 175.63 Y 77.14 tot 252.780 | Current: 18:55:13\n",
      "Epoch[16] Batch 50/128  Time 0.286s Data 0.125s || LOSS: CLS 0.006 X 165.57 Y 81.52 tot 247.094 | Current: 18:55:15\n",
      "Epoch[16] Batch 60/128  Time 0.266s Data 0.105s || LOSS: CLS 0.006 X 203.60 Y 93.16 tot 296.760 | Current: 18:55:17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-dc46a2e61271>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#step1 = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtr_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmicro_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_step\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoord_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmicro_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_micro\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoord_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_micro\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtest_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_imlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_imlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test_image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\[0_BigData_Acu]\\Acupuncture-Points\\CV_DeepLearning\\Training_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, coord_loss, class_loss, epoch, writer, micro_step, t_step, lambda1, lambda2, enable_gpu, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mcls_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mx_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0my_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#step1 = 0\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    tr_loss, micro_step, t_step =  train(model, train_loader, optimizer, coord_loss, class_loss, epoch, writer, micro_step, t_step)\n",
    "    val_loss, v_micro, v_step = validate(model, valid_loader, coord_loss, class_loss, epoch, writer, v_micro, v_step)\n",
    "    test_step = test(test_imlist, target_imlist, model, writer, 'test_image', test_step)\n",
    "    writer.flush()\n",
    "    \n",
    "    val_loss\n",
    "    is_best = sum(val_loss[0:2]) > best_val\n",
    "    best_val = min( sum(val_loss[0:2]), best_val )\n",
    "    \n",
    "    save_checkpoint({\n",
    "        'epoch' : epoch,\n",
    "        'model' : args.model, \n",
    "        'state_dict' : model.state_dict(),\n",
    "        'best_val' : best_val, \n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "        'scheduler' : scheduler.state_dict()\n",
    "    }, is_best, args.prefix)\n",
    "    \n",
    "    \n",
    "    \n",
    "#    scheduler.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.resume = './checkpoints/Hello_checkpoint.pth.tar'\n",
    "\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_val = checkpoint['best_val']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        if 'optimizer' in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test 체킹할때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, out2 = model(test_imlist[0].unsqueeze(0).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(test_imlist[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_imlist, target_imlist, model, writer, 'test_image', step = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1['image'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tb 체킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = iter(train_loader).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2 = model(d1['image'].to('cuda'))\n",
    "t1, t2, t3 = d1['image'], d1['target'], d1['label']\n",
    "img = np.transpose( to_numpy(t1[0]), (1,2,0))\n",
    "predicted =  to_numpy(p2[0])\n",
    "target = to_numpy(t2[0][1:])\n",
    "label = t3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data['sotack_0002983']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_change(img, target, predicted, label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = gen_train_monitor_plot(imgs, out2, x_ind = 0, y_ind = 1,target =  targets)\n",
    "imgs_grid = torchvision.utils.make_grid(img_list, normalize = True)\n",
    "writer = SummaryWriter(f'runs/hands')\n",
    "writer.add_image('imgs', imgs_grid)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
